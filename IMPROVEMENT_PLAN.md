# üöÄ Screenshot Tool Improvement Plan - 2024/2025 Best Practices

**Based on:** Latest online research + comprehensive code analysis  
**Date:** November 2, 2024  
**Priority:** Critical issues first, then optimizations

---

## üìä Research Summary

### Key Findings from 2024/2025 Best Practices:

1. **FastAPI State Management** ‚úÖ
   - Use `ContextVar` for request-scoped state (prevents race conditions)
   - Avoid global mutable state in async applications
   - Source: Medium article on Django/DRF variable scope (Aug 2025)

2. **Playwright Memory Management** ‚úÖ
   - Always close contexts to prevent memory leaks
   - Use context managers for automatic cleanup
   - Kill browser processes periodically for long-running tasks
   - Source: GitHub issue #15400, Stack Overflow discussions (2022-2024)

3. **React Performance** ‚úÖ
   - Debounce localStorage writes to reduce I/O
   - Use custom hooks for reusable logic
   - Memoization for heavy rendering
   - Source: Medium optimization guide (May 2024)

4. **Security Best Practices** ‚úÖ
   - Validate and sanitize file paths (prevent directory traversal)
   - Restrict CORS origins in production
   - Never expose sensitive data in logs
   - Source: Treblle API guide, Speakeasy file upload guide (2025)

5. **Playwright Stealth** ‚úÖ
   - Use playwright-stealth library (current implementation ‚úì)
   - Rotate user agents and proxies for large-scale scraping
   - CDP-based detection is most common
   - Source: ScrapingAnt guide (Sep 2024), Reddit discussions

6. **Python Logging** ‚úÖ
   - Use structured logging (structlog) for async applications
   - FastAPI built-in logging module integration
   - Rotating file handlers for production
   - Source: SigNoz guide (Jul 2024), Better Stack guide (May 2025)

7. **Code Quality Tools** ‚úÖ
   - MegaLinter for multi-language linting
   - Flake8, Pylint, Ruff for Python
   - GitLab CI/CD integration
   - Source: GitLab Docs, Homebrew Formulae

---

## üî¥ PHASE 1: Critical Fixes (Day 1-2)

### 1.1 Fix Global Cancellation Flag ‚ö° HIGHEST PRIORITY

**Issue:** Race condition in concurrent requests  
**Current Code:** `cancellation_flag = {"cancelled": False}`  
**Impact:** Multiple users will interfere with each other

**Solution (2024 Best Practice):**

```python
# backend/main.py
from contextvars import ContextVar
from uuid import uuid4

# Request-scoped cancellation tracking
cancellation_contexts: dict[str, dict] = {}

@app.post("/api/screenshots/capture")
async def capture_screenshots(request: URLRequest):
    # Create unique request ID
    request_id = str(uuid4())
    cancellation_contexts[request_id] = {"cancelled": False}
    
    try:
        # Pass request_id to service
        for i, url in enumerate(request.urls):
            # Check cancellation
            if cancellation_contexts[request_id]["cancelled"]:
                break
            
            result = await screenshot_service.capture(...)
            # ... rest of logic
    finally:
        # Cleanup
        cancellation_contexts.pop(request_id, None)

@app.post("/api/screenshots/cancel")
async def cancel_capture(request_id: str):
    if request_id in cancellation_contexts:
        cancellation_contexts[request_id]["cancelled"] = True
        return {"status": "cancelled"}
    return {"status": "not_found"}
```

**Effort:** 2 hours  
**Testing:** Test with 2+ concurrent capture requests

---

### 1.2 Fix CORS Security Vulnerability ‚ö° CRITICAL

**Issue:** `allow_origins=["*"]` allows any website to call your API  
**Risk:** CSRF attacks, unauthorized access

**Solution (2024 Best Practice):**

```python
# backend/main.py
import os
from fastapi.middleware.cors import CORSMiddleware

# Environment-based CORS configuration
ALLOWED_ORIGINS = os.getenv(
    "ALLOWED_ORIGINS",
    "http://localhost:1420,tauri://localhost,https://tauri.localhost"
).split(",")

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,  # Specific origins only
    allow_credentials=True,
    allow_methods=["GET", "POST", "DELETE"],  # Explicit methods
    allow_headers=["*"],
)
```

**Create `.env` file:**
```bash
# .env
ALLOWED_ORIGINS=http://localhost:1420,tauri://localhost
```

**Effort:** 30 minutes  
**Testing:** Verify Tauri app still works, test from different origin (should fail)

---

### 1.3 Fix Path Traversal Vulnerability ‚ö° CRITICAL

**Issue:** No validation on file paths - attacker could access `/etc/passwd`  
**Current Code:** `abs_path = os.path.abspath(file_path)`

**Solution (2024 Best Practice):**

```python
# backend/main.py
from pathlib import Path
from fastapi import HTTPException

def validate_screenshot_path(file_path: str) -> Path:
    """
    Validate file path to prevent directory traversal attacks.
    Ensures path is within screenshots directory.
    """
    try:
        # Resolve absolute paths
        requested_path = Path(file_path).resolve()
        screenshots_dir = Path("screenshots").resolve()
        
        # Check if path is within allowed directory
        if not requested_path.is_relative_to(screenshots_dir):
            raise ValueError("Path outside screenshots directory")
        
        # Check if file exists
        if not requested_path.exists():
            raise ValueError("File not found")
        
        return requested_path
    except Exception as e:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid file path: {str(e)}"
        )

@app.get("/api/screenshots/open/{file_path:path}")
async def open_file(file_path: str):
    # Validate path
    validated_path = validate_screenshot_path(file_path)
    
    # Open file
    os.startfile(str(validated_path))
    return {"status": "opened", "path": str(validated_path)}
```

**Effort:** 1 hour  
**Testing:** Try accessing `../../../etc/passwd` (should fail)

---

### 1.4 Implement Structured Logging ‚ö° HIGH PRIORITY

**Issue:** 100+ print statements, no log levels, no file output  
**Impact:** Cannot debug production issues

**Solution (2024 Best Practice - structlog):**

```python
# backend/logging_config.py
import logging
import sys
from logging.handlers import RotatingFileHandler
from pathlib import Path

def setup_logging():
    """Configure structured logging for the application"""
    
    # Create logs directory
    Path("logs").mkdir(exist_ok=True)
    
    # Configure root logger
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(levelname)-8s | %(name)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        handlers=[
            # Console handler (with colors in development)
            logging.StreamHandler(sys.stdout),
            
            # File handler (rotating, max 10MB, keep 5 backups)
            RotatingFileHandler(
                'logs/screenshot_tool.log',
                maxBytes=10_485_760,  # 10MB
                backupCount=5,
                encoding='utf-8'
            )
        ]
    )
    
    # Set levels for noisy libraries
    logging.getLogger("uvicorn.access").setLevel(logging.WARNING)
    logging.getLogger("playwright").setLevel(logging.WARNING)
    
    return logging.getLogger(__name__)

# Usage in files:
# from logging_config import setup_logging
# logger = setup_logging()
# logger.info("üìä Auth state contains: %d cookies", cookie_count)
# logger.warning("‚ö†Ô∏è No auth cookies found!")
# logger.error("‚ùå Failed to load cookies: %s", e)
```

**Update main.py:**
```python
# backend/main.py
from logging_config import setup_logging

logger = setup_logging()

@app.on_event("startup")
async def startup_event():
    logger.info("üöÄ Screenshot Tool API starting up...")
    logger.info("üìÅ Output directory: %s", Path("screenshots").resolve())
```

**Effort:** 4 hours (includes replacing print statements)  
**Testing:** Check logs/screenshot_tool.log file is created

---

## üü° PHASE 2: Performance Optimizations (Day 3-5)

### 2.1 Implement Parallel Screenshot Capture ‚ö° HIGH IMPACT

**Issue:** Sequential capture is slow (1 URL at a time)  
**Impact:** 10 URLs takes 10x longer than necessary

**Solution (2024 Best Practice - asyncio.Semaphore):**

```python
# backend/screenshot_service.py
import asyncio
from typing import List, Dict

class ScreenshotService:
    def __init__(self):
        self.browser = None
        self.playwright = None
        self.output_dir = Path("screenshots")
        self.session_dir = Path("browser_sessions")
        self.current_mode_is_real_browser = None
        self.max_concurrent = 3  # Limit concurrent captures
    
    async def capture_batch(
        self,
        urls: List[str],
        viewport_width: int = 1920,
        viewport_height: int = 1080,
        **kwargs
    ) -> List[Dict]:
        """
        Capture multiple URLs in parallel with semaphore limiting.
        
        Args:
            urls: List of URLs to capture
            max_concurrent: Maximum concurrent captures (default: 3)
            **kwargs: Other capture parameters
        
        Returns:
            List of capture results
        """
        semaphore = asyncio.Semaphore(self.max_concurrent)
        
        async def capture_with_semaphore(url: str, index: int):
            async with semaphore:
                try:
                    logger.info(f"üì∏ [{index+1}/{len(urls)}] Capturing: {url}")
                    result = await self.capture(
                        url=url,
                        viewport_width=viewport_width,
                        viewport_height=viewport_height,
                        **kwargs
                    )
                    return {"url": url, "status": "success", "result": result}
                except Exception as e:
                    logger.error(f"‚ùå [{index+1}/{len(urls)}] Failed {url}: {e}")
                    return {"url": url, "status": "failed", "error": str(e)}
        
        # Execute all captures in parallel (limited by semaphore)
        tasks = [capture_with_semaphore(url, i) for i, url in enumerate(urls)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        return results
```

**Update main.py to use batch capture:**
```python
# backend/main.py
@app.post("/api/screenshots/capture")
async def capture_screenshots(request: URLRequest):
    # ... setup code
    
    # Use parallel capture
    results = await screenshot_service.capture_batch(
        urls=request.urls,
        viewport_width=request.viewport_width,
        viewport_height=request.viewport_height,
        # ... other params
    )
    
    # ... process results
```

**Effort:** 1 day  
**Expected Improvement:** 3x faster for batches  
**Testing:** Capture 10 URLs, measure time before/after

---

### 2.2 Fix Browser Memory Leaks ‚ö° CRITICAL FOR LONG SESSIONS

**Issue:** Browser contexts not properly closed  
**Impact:** Memory grows over time, eventual crash

**Solution (2024 Best Practice - Context Managers):**

```python
# backend/screenshot_service.py
from contextlib import asynccontextmanager

class ScreenshotService:
    @asynccontextmanager
    async def browser_context(self, use_real_browser: bool = False, **context_options):
        """
        Context manager for browser contexts - ensures proper cleanup.
        
        Usage:
            async with service.browser_context() as context:
                page = await context.new_page()
                # ... use page
        """
        browser = await self._get_browser(use_real_browser)
        context = None
        
        try:
            context = await browser.new_context(**context_options)
            logger.debug("üåê Browser context created")
            yield context
        finally:
            if context:
                await context.close()
                logger.debug("üóëÔ∏è  Browser context closed")
    
    async def capture(self, url: str, **kwargs):
        """Updated capture method using context manager"""
        
        # ... setup code
        
        # Use context manager for automatic cleanup
        async with self.browser_context(
            use_real_browser=use_real_browser,
            viewport={'width': viewport_width, 'height': viewport_height},
            storage_state=storage_state,
            # ... other options
        ) as context:
            page = await context.new_page()
            
            try:
                # ... capture logic
                await page.screenshot(path=str(filepath))
                return str(filepath)
            finally:
                await page.close()
```

**Effort:** 4 hours  
**Testing:** Capture 100 URLs, monitor memory usage

---

### 2.3 Debounce localStorage Writes (Frontend) ‚ö° HIGH IMPACT

**Issue:** 20+ useEffect hooks writing to localStorage on every change  
**Impact:** Excessive I/O, poor performance

**Solution (2024 Best Practice - Custom Hook):**

```typescript
// frontend/src/hooks/useDebouncedLocalStorage.ts
import { useEffect, useRef } from 'react';

export function useDebouncedLocalStorage<T>(
  key: string,
  value: T,
  delay: number = 500
): void {
  const timeoutRef = useRef<NodeJS.Timeout>();

  useEffect(() => {
    // Clear previous timeout
    if (timeoutRef.current) {
      clearTimeout(timeoutRef.current);
    }

    // Set new timeout
    timeoutRef.current = setTimeout(() => {
      try {
        const serialized = JSON.stringify(value);
        localStorage.setItem(key, serialized);
        console.log(`üíæ Saved ${key} to localStorage`);
      } catch (error) {
        console.error(`Failed to save ${key}:`, error);
      }
    }, delay);

    // Cleanup on unmount
    return () => {
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
      }
    };
  }, [key, value, delay]);
}
```

**Update App.tsx:**
```typescript
// Replace all individual useEffect hooks with:
import { useDebouncedLocalStorage } from './hooks/useDebouncedLocalStorage';

function App() {
  const [urls, setUrls] = useState<string[]>([]);
  const [captureMode, setCaptureMode] = useState("viewport");
  // ... other state

  // Debounced localStorage writes
  useDebouncedLocalStorage("screenshot-urls", urls);
  useDebouncedLocalStorage("screenshot-capturemode", captureMode);
  useDebouncedLocalStorage("screenshot-sessions", sessions);
  // ... etc
```

**Effort:** 2 hours  
**Expected Improvement:** 90% reduction in localStorage writes  
**Testing:** Type in URL field rapidly, check console logs

---

## üü¢ PHASE 3: Code Quality (Day 6-10)

### 3.1 Extract Duplicate Code

**Issue:** 400+ lines duplicated between `capture()` and `capture_segmented()`

**Solution:**

```python
# backend/screenshot_service.py
class ScreenshotService:
    async def _load_auth_state(
        self,
        cookies: Optional[str],
        local_storage: Optional[str]
    ) -> Optional[str]:
        """
        Load authentication state from file or parameters.
        Returns storage_state path or None.
        """
        storage_state_file = Path("auth_state.json")
        
        if storage_state_file.exists() and not cookies and not local_storage:
            logger.info("üîê Loading saved auth state from %s", storage_state_file)
            
            # Verify contents
            with open(storage_state_file, 'r') as f:
                state_data = json.load(f)
                cookie_count = len(state_data.get('cookies', []))
                ls_count = sum(
                    len(origin.get('localStorage', []))
                    for origin in state_data.get('origins', [])
                )
                logger.info("   üìä Auth state: %d cookies, %d localStorage items",
                           cookie_count, ls_count)
            
            return str(storage_state_file)
        
        return None
    
    async def _configure_stealth_settings(
        self,
        use_stealth: bool,
        viewport_width: int,
        viewport_height: int
    ) -> dict:
        """Configure stealth settings for browser context"""
        settings = {}
        
        if use_stealth:
            # Randomize viewport slightly
            settings['viewport'] = {
                'width': viewport_width + random.randint(-10, 10),
                'height': viewport_height + random.randint(-10, 10)
            }
            
            # Random user agent
            user_agents = [
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64)...',
                # ... more user agents
            ]
            settings['user_agent'] = random.choice(user_agents)
            
            # Enhanced headers
            settings['extra_http_headers'] = {
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept-Encoding': 'gzip, deflate, br',
                # ... more headers
            }
        
        return settings
```

**Effort:** 1 day  
**Impact:** Reduces code by ~400 lines, easier maintenance

---

### 3.2 Add Configuration Management

Create centralized configuration:

```python
# backend/config.py
from pydantic_settings import BaseSettings
from typing import List

class Settings(BaseSettings):
    # API Settings
    API_HOST: str = "127.0.0.1"
    API_PORT: int = 8000
    ALLOWED_ORIGINS: str = "http://localhost:1420,tauri://localhost"
    
    # Browser Settings
    VIEWPORT_WIDTH: int = 1920
    VIEWPORT_HEIGHT: int = 1080
    MAX_CONCURRENT_CAPTURES: int = 3
    
    # Timeout Settings (seconds)
    CAPTURE_TIMEOUT_NORMAL: float = 35.0
    CAPTURE_TIMEOUT_STEALTH: float = 70.0
    CAPTURE_TIMEOUT_REAL_BROWSER: float = 60.0
    CAPTURE_TIMEOUT_SEGMENTED: float = 120.0
    
    # Wait Times (seconds)
    WAIT_REACT_RENDER: float = 5.0
    WAIT_CONTENT_LOAD: float = 2.0
    WAIT_CLOUDFLARE: float = 8.0
    WAIT_AUTH_STATE_SAVE: float = 60.0
    
    # Quality Thresholds
    MIN_FILE_SIZE: int = 5000
    MIN_BRIGHTNESS: int = 10
    MAX_BRIGHTNESS: int = 250
    QUALITY_PASS_THRESHOLD: float = 60.0
    
    # Logging
    LOG_LEVEL: str = "INFO"
    LOG_FILE: str = "logs/screenshot_tool.log"
    LOG_MAX_BYTES: int = 10_485_760  # 10MB
    LOG_BACKUP_COUNT: int = 5
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

# Global settings instance
settings = Settings()
```

**Effort:** 1 day  
**Impact:** Easy customization, environment-based config

---

## üìã Implementation Checklist

### Week 1: Critical Fixes
- [ ] Fix global cancellation flag (2h)
- [ ] Fix CORS security (30min)
- [ ] Fix path traversal (1h)
- [ ] Implement structured logging (4h)
- [ ] Test all fixes (2h)

### Week 2: Performance
- [ ] Implement parallel capture (1 day)
- [ ] Fix browser memory leaks (4h)
- [ ] Debounce localStorage (2h)
- [ ] Performance testing (4h)

### Week 3: Code Quality
- [ ] Extract duplicate code (1 day)
- [ ] Add configuration management (1 day)
- [ ] Code review and testing (1 day)

---

## üéØ Expected Results

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Concurrent Request Safety | ‚ùå Broken | ‚úÖ Safe | 100% |
| Security Score | 6/10 | 9/10 | +50% |
| Batch Capture Speed | 1x | 3x | +200% |
| Memory Leaks | ‚ö†Ô∏è Yes | ‚úÖ No | Fixed |
| localStorage Writes | 100% | 10% | -90% |
| Code Duplication | 400 lines | 0 lines | -100% |
| Maintainability | 50/100 | 75/100 | +50% |

---

**Next Steps:** Start with Phase 1 (Critical Fixes) - should I begin implementing?
